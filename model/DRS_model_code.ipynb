{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a01858f-0f5b-40e8-b014-db7152feb127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Policy_ID Policyholder_Name  Age  Gender Policy_Start_Date Policy_End_Date  \\\n",
      "0      10000      Norma Fisher   49  Female        2024-04-10      2025-04-10   \n",
      "1      10001    Colleen Taylor   64  Female        2024-02-24      2025-02-24   \n",
      "2      10002    Nicholas Nolan   60  Female        2024-09-22      2025-09-22   \n",
      "3      10003        Susan Levy   45    Male        2024-07-04      2025-07-04   \n",
      "4      10004         Ryan Page   44  Female        2024-09-16      2025-09-16   \n",
      "\n",
      "     Country Vehicle_Make Vehicle_Model  Vehicle_Year  ... Annual_Premium  \\\n",
      "0      China       Cruise        Origin          2022  ...           1166   \n",
      "1      China       Cruise          Bolt          2019  ...           1283   \n",
      "2  Singapore         Nuro      Delivery          2019  ...            895   \n",
      "3      China         Nuro            R2          2020  ...           1258   \n",
      "4      China         Nuro      Delivery          2023  ...           1360   \n",
      "\n",
      "  Deductible Claim_History  Last_Claim_Date  Claim_Amount  Safety_Score  \\\n",
      "0        598             1       2024-08-14          4134            68   \n",
      "1        586             0              NaT             0            82   \n",
      "2        668             3       2024-05-02             9            99   \n",
      "3        346             0              NaT             0            80   \n",
      "4        600             2       2024-09-30          3645            65   \n",
      "\n",
      "  Num_Accidents  IoT_Monitoring  Past_Fraud_Record  Policy_Status  \n",
      "0             2             Yes                  0         Active  \n",
      "1             3              No                  0         Active  \n",
      "2             3              No                  0         Active  \n",
      "3             4              No                  0         Active  \n",
      "4             4              No                  1         Active  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker and set seed for reproducibility\n",
    "fake = Faker()\n",
    "Faker.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Define possible values for some fields\n",
    "vehicle_makes = [\"Tesla\", \"Waymo\", \"Cruise\", \"Rivian\", \"Nuro\", \"Zoox\"]\n",
    "vehicle_models = {\n",
    "    \"Tesla\": [\"Model S\", \"Model X\", \"Model 3\", \"Model Y\", \"Cybertruck\"],\n",
    "    \"Waymo\": [\"Jaguar I-Pace\", \"RoboTaxi\", \"Firefly\"],\n",
    "    \"Cruise\": [\"Bolt\", \"Origin\"],\n",
    "    \"Rivian\": [\"R1T\", \"R1S\"],\n",
    "    \"Nuro\": [\"R2\", \"Delivery\"],\n",
    "    \"Zoox\": [\"Autonomous\"]\n",
    "}\n",
    "autonomy_levels = [\"Level 3\", \"Level 4\", \"Level 5\"]\n",
    "coverage_types = [\"Basic\", \"Collision\", \"Comprehensive\"]\n",
    "genders = [\"Male\", \"Female\"]\n",
    "countries = [\"China\", \"Singapore\"]\n",
    "fraud_prob = [0, 1]  # 0 = No Fraud, 1 = Fraud\n",
    "\n",
    "# Helper function to generate random data with fraud column\n",
    "def generate_policy_data_with_fraud(num_records=1000):\n",
    "    data = []\n",
    "    for i in range(num_records):\n",
    "        policy_id = 10000 + i\n",
    "        policyholder_name = fake.name()\n",
    "        age = random.randint(25, 70)\n",
    "        gender = random.choice(genders)\n",
    "        policy_start_date = pd.to_datetime(fake.date_this_year(before_today=True, after_today=False))\n",
    "        policy_end_date = policy_start_date + pd.DateOffset(years=1)\n",
    "        country = random.choice(countries)\n",
    "        vehicle_make = random.choice(vehicle_makes)\n",
    "        vehicle_model = random.choice(vehicle_models[vehicle_make])\n",
    "        vehicle_year = random.randint(2019, 2023)\n",
    "        autonomy_level = random.choice(autonomy_levels)\n",
    "        vin = fake.bothify(text='1HGCM82633A######', letters='0123456789')\n",
    "        coverage_type = random.choice(coverage_types)\n",
    "        annual_premium = random.randint(800, 1500)\n",
    "        deductible = random.randint(300, 700)\n",
    "        claim_history = random.randint(0, 3)\n",
    "        last_claim_date = pd.to_datetime(fake.date_this_year()) if claim_history > 0 else pd.NaT\n",
    "        claim_amount = random.randint(0, 5000) if claim_history > 0 else 0\n",
    "        safety_score = random.randint(60, 100)\n",
    "        num_accidents = random.randint(0, 5)\n",
    "        iot_monitoring = random.choice([\"Yes\", \"No\"])\n",
    "        past_fraud_record = random.choice(fraud_prob)  # Adding fraud record column\n",
    "        \n",
    "        # Determine policy status\n",
    "        current_date = pd.Timestamp.now()\n",
    "        policy_status = \"Active\" if policy_end_date > current_date else random.choice([\"Expired\", \"Canceled\"])\n",
    "\n",
    "        data.append([\n",
    "            policy_id, policyholder_name, age, gender, policy_start_date, policy_end_date,\n",
    "            country, vehicle_make, vehicle_model, vehicle_year, autonomy_level, vin,\n",
    "            coverage_type, annual_premium, deductible, claim_history, last_claim_date,\n",
    "            claim_amount, safety_score, num_accidents, iot_monitoring, past_fraud_record, policy_status\n",
    "        ])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        \"Policy_ID\", \"Policyholder_Name\", \"Age\", \"Gender\", \"Policy_Start_Date\", \"Policy_End_Date\",\n",
    "        \"Country\", \"Vehicle_Make\", \"Vehicle_Model\", \"Vehicle_Year\", \"Autonomy_Level\", \"VIN\",\n",
    "        \"Coverage_Type\", \"Annual_Premium\", \"Deductible\", \"Claim_History\", \"Last_Claim_Date\",\n",
    "        \"Claim_Amount\", \"Safety_Score\", \"Num_Accidents\", \"IoT_Monitoring\", \"Past_Fraud_Record\", \"Policy_Status\"\n",
    "    ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate synthetic policy data\n",
    "num_records = 1000\n",
    "df_policy = generate_policy_data_with_fraud(num_records)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df_policy.head())\n",
    "\n",
    "# Save to CSV\n",
    "# output_path = r\"C:\\Users\\Soumya Haridas\\Downloads\\synthetic_policy_data_with_fraud.csv\"\n",
    "# df_policy.to_csv(output_path, index=False)\n",
    "\n",
    "# print(f\"CSV file saved as '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877133be-7741-4501-baba-53093c9534ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##OLD CODE THAT WORKS - RANDOMFOREST\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Load the synthetic policy data generated previously\n",
    "# #df_policy = pd.read_csv(r\"C:\\Users\\Soumya Haridas\\Downloads\\synthetic_policy_data_with_fraud.csv\")\n",
    "\n",
    "# # Step 2.1: Feature Engineering\n",
    "# # Encode categorical variables\n",
    "# label_encoders = {}\n",
    "# for column in [\"Gender\", \"Country\", \"Vehicle_Make\", \"Vehicle_Model\", \"Autonomy_Level\", \n",
    "#                \"Coverage_Type\", \"IoT_Monitoring\", \"Policy_Status\"]:\n",
    "#     le = LabelEncoder()\n",
    "#     df_policy[column] = le.fit_transform(df_policy[column])\n",
    "#     label_encoders[column] = le\n",
    "\n",
    "# # Convert date columns to numeric (timestamp)\n",
    "# df_policy['Policy_Start_Date'] = pd.to_datetime(df_policy['Policy_Start_Date']).astype('int64') // 10**9\n",
    "# df_policy['Policy_End_Date'] = pd.to_datetime(df_policy['Policy_End_Date']).astype('int64') // 10**9\n",
    "\n",
    "# # Handle 'Last_Claim_Date' column by replacing NaT with a default value before conversion\n",
    "# df_policy['Last_Claim_Date'] = pd.to_datetime(df_policy['Last_Claim_Date'], errors='coerce')\n",
    "\n",
    "# # Replace NaT with 0 (or a default timestamp, e.g., 0 for no claim history)\n",
    "# df_policy['Last_Claim_Date'] = df_policy['Last_Claim_Date'].fillna(pd.Timestamp(0))\n",
    "# df_policy['Last_Claim_Date'] = df_policy['Last_Claim_Date'].astype('int64') // 10**9\n",
    "\n",
    "# # Select features and target for ML model\n",
    "# features = [\"Age\", \"Gender\", \"Country\", \"Vehicle_Make\", \"Vehicle_Model\", \"Vehicle_Year\",\n",
    "#             \"Autonomy_Level\", \"Coverage_Type\", \"Annual_Premium\", \"Deductible\", \"Claim_History\",\n",
    "#             \"Claim_Amount\", \"Safety_Score\", \"Num_Accidents\", \"IoT_Monitoring\", \"Past_Fraud_Record\"]\n",
    "# X = df_policy[features]\n",
    "# y = df_policy[\"Safety_Score\"]  # Using safety score as a proxy for initial ML-based risk score\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# # Step 2.2: Train an ML Model\n",
    "# # Use Random Forest to predict risk score\n",
    "# rf_model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# # Calculate the mean squared error for model evaluation\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(f\"Mean Squared Error of the model: {mse:.4f}\")\n",
    "\n",
    "# # Step 2.3: Combine ML Risk Score and Rule-Based Criteria\n",
    "# # Predict risk scores on the entire dataset\n",
    "# df_policy[\"ML_Risk_Score\"] = rf_model.predict(X)\n",
    "\n",
    "# # Calculate dynamic risk score (DRS)\n",
    "# def calculate_dynamic_risk_score(row):\n",
    "#     risk_score = row[\"ML_Risk_Score\"]\n",
    "    \n",
    "#     # Rule-based adjustments\n",
    "#     if row[\"Num_Accidents\"] >= 3:\n",
    "#         risk_score += 10  # Increase risk for higher number of accidents\n",
    "#     if row[\"Past_Fraud_Record\"] == 1:\n",
    "#         risk_score += 20  # Increase risk if there is a past fraud record\n",
    "\n",
    "#     return risk_score\n",
    "\n",
    "# df_policy[\"Dynamic_Risk_Score\"] = df_policy.apply(calculate_dynamic_risk_score, axis=1)\n",
    "\n",
    "# # Step 2.4: Categorize the Dynamic Risk Score\n",
    "# def categorize_risk(drs):\n",
    "#     if drs < 40:\n",
    "#         return \"LOW\"\n",
    "#     elif 40 <= drs < 60:\n",
    "#         return \"MEDIUM\"\n",
    "#     elif 60 <= drs < 70:\n",
    "#         return \"HIGH A\"\n",
    "#     elif 70 <= drs < 80:\n",
    "#         return \"HIGH B\"\n",
    "#     else:\n",
    "#         return \"VERY HIGH\"\n",
    "\n",
    "# df_policy[\"Risk_Category\"] = df_policy[\"Dynamic_Risk_Score\"].apply(categorize_risk)\n",
    "\n",
    "# # Display the first few rows of the dataframe with DRS and Risk Category\n",
    "# print(df_policy[[\"Policy_ID\", \"ML_Risk_Score\", \"Dynamic_Risk_Score\", \"Risk_Category\"]].head())\n",
    "\n",
    "# # Save the final dataset with Dynamic Risk Score\n",
    "# output_path_final = r\"C:\\Users\\Soumya Haridas\\Downloads\\policy_data_with_drs.csv\"\n",
    "# df_policy.to_csv(output_path_final, index=False)\n",
    "# print(f\"Final dataset with DRS saved as '{output_path_final}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4bc69d-3af7-4236-9c32-09fd4bb24d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of Voting Regressor: 0.0000\n",
      "Mean Squared Error of Stacking Regressor: 0.0000\n",
      "   Policy_ID  ML_Risk_Score  Dynamic_Risk_Score Risk_Category\n",
      "0      10000      67.999857           67.999857        HIGH A\n",
      "1      10001      82.000034           92.000034     VERY HIGH\n",
      "2      10002      98.999914          108.999914     VERY HIGH\n",
      "3      10003      79.999999           89.999999     VERY HIGH\n",
      "4      10004      64.999839           94.999839     VERY HIGH\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess data (excluding 'Policy_Status' if it doesn't exist)\n",
    "label_encoders = {}\n",
    "for column in [\"Gender\", \"Country\", \"Vehicle_Make\", \"Vehicle_Model\", \"Autonomy_Level\", \n",
    "               \"Coverage_Type\", \"IoT_Monitoring\"]:\n",
    "    le = LabelEncoder()\n",
    "    df_policy[column] = le.fit_transform(df_policy[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Continue with the existing preprocessing steps...\n",
    "# Convert date columns to numeric (timestamp)\n",
    "df_policy['Policy_Start_Date'] = pd.to_datetime(df_policy['Policy_Start_Date']).astype('int64') // 10**9\n",
    "df_policy['Policy_End_Date'] = pd.to_datetime(df_policy['Policy_End_Date']).astype('int64') // 10**9\n",
    "df_policy['Last_Claim_Date'] = pd.to_datetime(df_policy['Last_Claim_Date'], errors='coerce').fillna(pd.Timestamp(0))\n",
    "df_policy['Last_Claim_Date'] = df_policy['Last_Claim_Date'].astype('int64') // 10**9\n",
    "\n",
    "# Select features and target\n",
    "features = [\"Age\", \"Gender\", \"Country\", \"Vehicle_Make\", \"Vehicle_Model\", \"Vehicle_Year\",\n",
    "            \"Autonomy_Level\", \"Coverage_Type\", \"Annual_Premium\", \"Deductible\", \"Claim_History\",\n",
    "            \"Claim_Amount\", \"Safety_Score\", \"Num_Accidents\", \"IoT_Monitoring\", \"Past_Fraud_Record\"]\n",
    "X = df_policy[features]\n",
    "y = df_policy[\"Safety_Score\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Continue with ensemble model creation...\n",
    "\n",
    "\n",
    "### Step 2: Create an Ensemble Model\n",
    "\n",
    "# Define base models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=0)\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Create a Voting Regressor\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('rf', rf_model), \n",
    "    ('gb', gb_model), \n",
    "    ('lr', lr_model)\n",
    "])\n",
    "\n",
    "# Create a Stacking Regressor\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', rf_model), \n",
    "        ('gb', gb_model)\n",
    "    ],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# Fit the ensemble models on training data\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using the ensemble models\n",
    "y_pred_voting = voting_regressor.predict(X_test)\n",
    "y_pred_stacking = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse_voting = mean_squared_error(y_test, y_pred_voting)\n",
    "mse_stacking = mean_squared_error(y_test, y_pred_stacking)\n",
    "\n",
    "print(f\"Mean Squared Error of Voting Regressor: {mse_voting:.4f}\")\n",
    "print(f\"Mean Squared Error of Stacking Regressor: {mse_stacking:.4f}\")\n",
    "\n",
    "### Step 3: Combine ML Risk Score and Rule-Based Criteria\n",
    "\n",
    "# Use the Stacking Regressor's prediction as the ML risk score\n",
    "df_policy[\"ML_Risk_Score\"] = stacking_regressor.predict(X)\n",
    "\n",
    "# Calculate dynamic risk score (DRS)\n",
    "def calculate_dynamic_risk_score(row):\n",
    "    risk_score = row[\"ML_Risk_Score\"]\n",
    "    # Rule-based adjustments\n",
    "    if row[\"Num_Accidents\"] >= 3:\n",
    "        risk_score += 10\n",
    "    if row[\"Past_Fraud_Record\"] == 1:\n",
    "        risk_score += 20\n",
    "    return risk_score\n",
    "\n",
    "df_policy[\"Dynamic_Risk_Score\"] = df_policy.apply(calculate_dynamic_risk_score, axis=1)\n",
    "\n",
    "# Categorize the Dynamic Risk Score\n",
    "def categorize_risk(drs):\n",
    "    if drs < 40:\n",
    "        return \"LOW\"\n",
    "    elif 40 <= drs < 60:\n",
    "        return \"MEDIUM\"\n",
    "    elif 60 <= drs < 70:\n",
    "        return \"HIGH A\"\n",
    "    elif 70 <= drs < 80:\n",
    "        return \"HIGH B\"\n",
    "    else:\n",
    "        return \"VERY HIGH\"\n",
    "\n",
    "df_policy[\"Risk_Category\"] = df_policy[\"Dynamic_Risk_Score\"].apply(categorize_risk)\n",
    "\n",
    "# Display the final output\n",
    "print(df_policy[[\"Policy_ID\", \"ML_Risk_Score\", \"Dynamic_Risk_Score\", \"Risk_Category\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e8652e-192b-42b0-b7b5-5ca4bf0f27ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'stacking_regressor_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the Stacking Regressor as a .pkl file\n",
    "with open('stacking_regressor_model.pkl', 'wb') as file:\n",
    "    pickle.dump(stacking_regressor, file)\n",
    "\n",
    "print(\"Model saved as 'stacking_regressor_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c9690c-511f-40d4-94c7-3932f035098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ML_Risk_Score  Dynamic_Risk_Score Risk_Category\n",
      "0       85.00006            85.00006     VERY HIGH\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe772ca-643c-4edd-8073-c5b1c4db8074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
